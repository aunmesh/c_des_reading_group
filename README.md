# C Design Lab Machine Learning Reading Group
* **Datetime** : 11:00 AM on Mon, Wed, and Fri every week\
* **Participants** : Asim, Hyung-gun \
* **WebEx link** : [https://purdue-student.webex.com/meet/chi45](https://purdue-student.webex.com/meet/chi45)

## Before 4 May:

**Hyung Gun**
* [3D Hand Pose Estimation in the Wild via Graph Refinement under Adversarial Learning](https://arxiv.org/pdf/1912.01875.pdf)

* [PoseFix: Model-agnostic General Human Pose Refinement Network](https://arxiv.org/abs/1812.03595)

* [Fast Online Object Tracking and Segmentation: A Unifying Approach](http://www.robots.ox.ac.uk/~qwang/SiamMask/ )

* [Learning feed-forward one-shot learners](https://arxiv.org/pdf/1606.05233.pdf )

* [Learning Pose Specific Representations by Predicting Different Views](https://arxiv.org/pdf/1804.03390v2.pdf )

* [Weakly-Supervised Mesh-Convolutional Hand Reconstruction in the Wild ](https://arxiv.org/pdf/2004.01946.pdf)

* [ViewAL: Active Learning With Viewpoint Entropy for Semantic Segmentation ](https://arxiv.org/pdf/1911.11789.pdf )

* [Temporal Cycle-Consistency Learning](https://arxiv.org/pdf/1904.07846.pdf )

* [PointRend: Image Segmentation as Rendering](https://arxiv.org/pdf/1912.08193.pdf )

* [Learning to Regress 3D Face Shape and Expression from an Image without 3D Supervision](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/509/paper_camera_ready.pdf)


**Asim**
* [Learning by Association -- A Versatile Semi-Supervised Training Method for Neural Networks](http://openaccess.thecvf.com/content_cvpr_2017/papers/Haeusser_Learning_by_Association_CVPR_2017_paper.pdf)

* [Active 6D Multi-Object Pose Estimation in Cluttered Scenarios with Deep Reinforcement Learning](https://arxiv.org/pdf/1910.08811.pdf)

* [Iterative Instance Segmentation](https://arxiv.org/pdf/1511.08498.pdf)

* [Learning to Generate Synthetic Data via Compositing](http://openaccess.thecvf.com/content_CVPR_2019/papers/Tripathi_Learning_to_Generate_Synthetic_Data_via_Compositing_CVPR_2019_paper.pdf)

* [Learning Loss for Active Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yoo_Learning_Loss_for_Active_Learning_CVPR_2019_paper.pdf)

* [Improving the Robustness of Deep Neural Networks via Stability Training](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zheng_Improving_the_Robustness_CVPR_2016_paper.pdf)

* [How transferable are features in Deep Neural Networks](https://arxiv.org/pdf/1411.1792.pdf)

* [MMSS: Multi-Modal Sharable and Specific Feature Learning for RGB-D Object Recognition](http://openaccess.thecvf.com/content_iccv_2015/papers/Wang_MMSS_Multi-Modal_Sharable_ICCV_2015_paper.pdf)

* [Learning Descriptors for Object Recognition and 3D Pose Estimation](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wohlhart_Learning_Descriptors_for_2015_CVPR_paper.pdf)



## 4 May

**Hyung Gun**
[Leveraging Photometric Consistency over Time for Sparsely Supervised Hand-Object Reconstruction](https://arxiv.org/pdf/2004.13449.pdf)

> Uses photometric consistency to propagate annotations to un-annotated frames.

**Asim**
[Sim2real transfer learning for 3D human pose
estimation: motion to the rescue](https://papers.nips.cc/paper/9454-sim2real-transfer-learning-for-3d-human-pose-estimation-motion-to-the-rescue.pdf)

> Proposes using optical flow and 2d keypoints as input for pose estimation networks. Since these inputs are not affected by photorealism , hence can be trained well using synthetic data, without suffering much performance drop for real data.



## 6 May

**Hyung Gun**
[Self-Supervised GANs via Auxiliary Rotation Loss](https://arxiv.org/pdf/1811.11212.pdf)

> The role of self-supervision is to encourage the discriminator to learn meaningful feature repesentations which are not forgotten during training. The self-supervised GAN attains a similar performance to state-of-the-art conditional GAN.

**Asim**
[Cross-modal deep Variational hand pose estimation](http://openaccess.thecvf.com/content_cvpr_2018/papers/Spurr_Cross-Modal_Deep_Variational_CVPR_2018_paper.pdf)

> Uses different decoders from jointly obtained multi modal data to a joint latent space and does reconstruction from that. Is able to train using instances where all modalities are not available but a few are. Using this latent space they can train for hand pose estimation.
